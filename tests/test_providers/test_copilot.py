"""Unit tests for the CopilotProvider implementation."""

import contextlib
from typing import Any

import pytest

from copilot_conductor.config.schema import AgentDef
from copilot_conductor.exceptions import ProviderError
from copilot_conductor.providers.copilot import CopilotProvider, RetryConfig


def stub_handler(agent: AgentDef, prompt: str, context: dict[str, Any]) -> dict[str, Any]:
    """A simple mock handler that returns stub responses."""
    return {"result": "stub response"}


class TestCopilotProvider:
    """Tests for the CopilotProvider class."""

    @pytest.mark.asyncio
    async def test_validate_connection(self) -> None:
        """Test that validate_connection returns True with mock handler."""
        provider = CopilotProvider(mock_handler=stub_handler)
        result = await provider.validate_connection()
        assert result is True

    @pytest.mark.asyncio
    async def test_close(self) -> None:
        """Test that close cleans up the client."""
        provider = CopilotProvider(mock_handler=stub_handler)
        provider._client = "some_client"  # Simulate having a client
        await provider.close()
        assert provider._client is None

    @pytest.mark.asyncio
    async def test_execute_returns_stub_output(self) -> None:
        """Test that execute returns a stub AgentOutput."""
        provider = CopilotProvider(mock_handler=stub_handler)
        agent = AgentDef(
            name="test_agent",
            model="gpt-4",
            prompt="Test prompt",
        )
        result = await provider.execute(
            agent=agent,
            context={"workflow": {"input": {}}},
            rendered_prompt="Test prompt",
        )
        assert result.content == {"result": "stub response"}
        assert result.model == "gpt-4"
        assert result.tokens_used == 0

    @pytest.mark.asyncio
    async def test_execute_uses_agent_model(self) -> None:
        """Test that execute uses the model from agent definition."""
        provider = CopilotProvider(mock_handler=stub_handler)
        agent = AgentDef(
            name="test_agent",
            model="claude-3",
            prompt="Test prompt",
        )
        result = await provider.execute(
            agent=agent,
            context={},
            rendered_prompt="Test prompt",
        )
        assert result.model == "claude-3"

    @pytest.mark.asyncio
    async def test_execute_with_no_model(self) -> None:
        """Test that execute handles agent without model."""
        provider = CopilotProvider(mock_handler=stub_handler)
        # Create agent with type="human_gate" to bypass model requirement
        # or just set model to None directly
        agent = AgentDef(
            name="test_agent",
            prompt="Test prompt",
            model=None,
        )
        result = await provider.execute(
            agent=agent,
            context={},
            rendered_prompt="Test prompt",
        )
        assert result.model == "mock"


class TestCopilotProviderToolsSupport:
    """Tests for tool support in CopilotProvider."""

    @pytest.mark.asyncio
    async def test_execute_records_tools_in_call_history(self) -> None:
        """Test that tools are recorded in call history."""
        provider = CopilotProvider(mock_handler=stub_handler)
        agent = AgentDef(
            name="test_agent",
            model="gpt-4",
            prompt="Test prompt",
        )

        tools = ["web_search", "calculator"]
        await provider.execute(
            agent=agent,
            context={},
            rendered_prompt="Test prompt",
            tools=tools,
        )

        call_history = provider.get_call_history()
        assert len(call_history) == 1
        assert call_history[0]["tools"] == ["web_search", "calculator"]

    @pytest.mark.asyncio
    async def test_execute_with_empty_tools_list(self) -> None:
        """Test that empty tools list is recorded correctly."""
        provider = CopilotProvider(mock_handler=stub_handler)
        agent = AgentDef(
            name="test_agent",
            model="gpt-4",
            prompt="Test prompt",
        )

        await provider.execute(
            agent=agent,
            context={},
            rendered_prompt="Test prompt",
            tools=[],
        )

        call_history = provider.get_call_history()
        assert call_history[0]["tools"] == []

    @pytest.mark.asyncio
    async def test_execute_with_none_tools(self) -> None:
        """Test that None tools is recorded correctly."""
        provider = CopilotProvider(mock_handler=stub_handler)
        agent = AgentDef(
            name="test_agent",
            model="gpt-4",
            prompt="Test prompt",
        )

        await provider.execute(
            agent=agent,
            context={},
            rendered_prompt="Test prompt",
            tools=None,
        )

        call_history = provider.get_call_history()
        assert call_history[0]["tools"] is None

    @pytest.mark.asyncio
    async def test_mock_handler_receives_correct_tools(self) -> None:
        """Test that mock handler can verify tools passed to provider."""

        def mock_handler(agent: Any, prompt: Any, context: Any) -> dict[str, Any]:
            return {"result": "ok"}

        provider = CopilotProvider(mock_handler=mock_handler)
        agent = AgentDef(
            name="test_agent",
            model="gpt-4",
            prompt="Test prompt",
        )

        tools = ["scrape_url", "file_read"]
        await provider.execute(
            agent=agent,
            context={},
            rendered_prompt="Test prompt",
            tools=tools,
        )

        # Verify via call history
        call_history = provider.get_call_history()
        assert call_history[0]["tools"] == ["scrape_url", "file_read"]

    @pytest.mark.asyncio
    async def test_multiple_agents_with_different_tools(self) -> None:
        """Test that multiple agent calls track tools independently."""
        provider = CopilotProvider(mock_handler=stub_handler)

        agent1 = AgentDef(name="agent1", model="gpt-4", prompt="Prompt 1")
        agent2 = AgentDef(name="agent2", model="gpt-4", prompt="Prompt 2")
        agent3 = AgentDef(name="agent3", model="gpt-4", prompt="Prompt 3")

        await provider.execute(agent1, {}, "Prompt 1", tools=["tool_a", "tool_b"])
        await provider.execute(agent2, {}, "Prompt 2", tools=[])
        await provider.execute(agent3, {}, "Prompt 3", tools=None)

        history = provider.get_call_history()
        assert len(history) == 3
        assert history[0]["agent_name"] == "agent1"
        assert history[0]["tools"] == ["tool_a", "tool_b"]
        assert history[1]["agent_name"] == "agent2"
        assert history[1]["tools"] == []
        assert history[2]["agent_name"] == "agent3"
        assert history[2]["tools"] is None


class TestCopilotProviderRetryLogic:
    """Tests for retry logic in CopilotProvider."""

    @pytest.mark.asyncio
    async def test_successful_call_no_retry(self) -> None:
        """Test that successful calls don't trigger retries."""
        call_count = 0

        def mock_handler(agent, prompt, context):
            nonlocal call_count
            call_count += 1
            return {"result": "success"}

        provider = CopilotProvider(mock_handler=mock_handler)
        agent = AgentDef(name="test", model="gpt-4", prompt="Test")

        result = await provider.execute(agent, {}, "Test")

        assert result.content["result"] == "success"
        assert call_count == 1
        assert len(provider.get_retry_history()) == 0

    @pytest.mark.asyncio
    async def test_retryable_error_retries(self) -> None:
        """Test that retryable errors are retried."""
        call_count = 0

        def mock_handler(agent, prompt, context):
            nonlocal call_count
            call_count += 1
            if call_count < 3:
                raise ProviderError("Server error", status_code=500)
            return {"result": "success after retry"}

        retry_config = RetryConfig(
            max_attempts=3,
            base_delay=0.01,  # Fast for testing
            max_delay=0.1,
        )
        provider = CopilotProvider(mock_handler=mock_handler, retry_config=retry_config)
        agent = AgentDef(name="test", model="gpt-4", prompt="Test")

        result = await provider.execute(agent, {}, "Test")

        assert result.content["result"] == "success after retry"
        assert call_count == 3
        retry_history = provider.get_retry_history()
        assert len(retry_history) == 2  # 2 failures before success

    @pytest.mark.asyncio
    async def test_non_retryable_error_fails_immediately(self) -> None:
        """Test that non-retryable errors fail without retry."""
        call_count = 0

        def mock_handler(agent, prompt, context):
            nonlocal call_count
            call_count += 1
            raise ProviderError("Unauthorized", status_code=401)

        provider = CopilotProvider(mock_handler=mock_handler)
        agent = AgentDef(name="test", model="gpt-4", prompt="Test")

        with pytest.raises(ProviderError) as exc_info:
            await provider.execute(agent, {}, "Test")

        assert call_count == 1  # Only one call, no retries
        assert exc_info.value.status_code == 401

    @pytest.mark.asyncio
    async def test_max_retries_exhausted(self) -> None:
        """Test that max retries are exhausted and then fails."""
        call_count = 0

        def mock_handler(agent, prompt, context):
            nonlocal call_count
            call_count += 1
            raise ProviderError("Server error", status_code=500)

        retry_config = RetryConfig(
            max_attempts=3,
            base_delay=0.01,
            max_delay=0.1,
        )
        provider = CopilotProvider(mock_handler=mock_handler, retry_config=retry_config)
        agent = AgentDef(name="test", model="gpt-4", prompt="Test")

        with pytest.raises(ProviderError) as exc_info:
            await provider.execute(agent, {}, "Test")

        assert call_count == 3
        assert "3 attempts" in str(exc_info.value)
        assert not exc_info.value.is_retryable

    @pytest.mark.asyncio
    async def test_rate_limit_429_is_retried(self) -> None:
        """Test that 429 rate limit errors are retried."""
        call_count = 0

        def mock_handler(agent, prompt, context):
            nonlocal call_count
            call_count += 1
            if call_count == 1:
                raise ProviderError("Rate limited", status_code=429)
            return {"result": "success"}

        retry_config = RetryConfig(
            max_attempts=3,
            base_delay=0.01,
            max_delay=0.1,
        )
        provider = CopilotProvider(mock_handler=mock_handler, retry_config=retry_config)
        agent = AgentDef(name="test", model="gpt-4", prompt="Test")

        result = await provider.execute(agent, {}, "Test")

        assert result.content["result"] == "success"
        assert call_count == 2

    @pytest.mark.asyncio
    async def test_retry_delay_increases_exponentially(self) -> None:
        """Test that retry delays increase exponentially."""
        call_count = 0

        def mock_handler(agent, prompt, context):
            nonlocal call_count
            call_count += 1
            if call_count < 3:
                raise ProviderError("Server error", status_code=500)
            return {"result": "success"}

        retry_config = RetryConfig(
            max_attempts=3,
            base_delay=1.0,
            max_delay=30.0,
            jitter=0.0,  # No jitter for predictable testing
        )
        provider = CopilotProvider(mock_handler=mock_handler, retry_config=retry_config)

        # Note: We can't easily test actual delays without mocking asyncio.sleep
        # but we can verify the delays recorded in retry history
        provider._calculate_delay(1, retry_config)  # 1 * 2^0 = 1.0
        provider._calculate_delay(2, retry_config)  # 1 * 2^1 = 2.0
        provider._calculate_delay(3, retry_config)  # 1 * 2^2 = 4.0

        # Just verify the method works
        assert provider._calculate_delay(1, retry_config) == 1.0
        assert provider._calculate_delay(2, retry_config) == 2.0
        assert provider._calculate_delay(3, retry_config) == 4.0

    @pytest.mark.asyncio
    async def test_retry_config_can_be_updated(self) -> None:
        """Test that retry config can be updated after creation."""
        provider = CopilotProvider()

        new_config = RetryConfig(max_attempts=5, base_delay=2.0)
        provider.set_retry_config(new_config)

        assert provider._retry_config.max_attempts == 5
        assert provider._retry_config.base_delay == 2.0

    @pytest.mark.asyncio
    async def test_retry_history_is_cleared_on_close(self) -> None:
        """Test that retry history is cleared when provider is closed."""
        def mock_handler(agent, prompt, context):
            raise ProviderError("Server error", status_code=500)

        retry_config = RetryConfig(max_attempts=2, base_delay=0.01)
        provider = CopilotProvider(mock_handler=mock_handler, retry_config=retry_config)

        with contextlib.suppress(ProviderError):
            await provider.execute(
                AgentDef(name="test", model="gpt-4", prompt="Test"),
                {},
                "Test",
            )

        assert len(provider.get_retry_history()) > 0

        await provider.close()
        assert len(provider.get_retry_history()) == 0


class TestRetryConfig:
    """Tests for RetryConfig dataclass."""

    def test_default_values(self) -> None:
        """Test default configuration values."""
        config = RetryConfig()
        assert config.max_attempts == 3
        assert config.base_delay == 1.0
        assert config.max_delay == 30.0
        assert config.jitter == 0.25

    def test_custom_values(self) -> None:
        """Test custom configuration values."""
        config = RetryConfig(
            max_attempts=5,
            base_delay=2.0,
            max_delay=60.0,
            jitter=0.5,
        )
        assert config.max_attempts == 5
        assert config.base_delay == 2.0
        assert config.max_delay == 60.0
        assert config.jitter == 0.5
